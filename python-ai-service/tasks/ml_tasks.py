#!/usr/bin/env python3
"""
ML Training & Analysis Tasks
Long-running machine learning operations executed asynchronously

IMPORTANT: These tasks now fetch REAL market data from Rust API.
Never use dummy/fake data for trading decisions!
"""

import asyncio
import os
from typing import Dict, Any, List
from celery import Task
from celery_app import app
from models.model_manager import ModelManager
from utils.logger import get_logger
import pandas as pd
import numpy as np
import httpx

logger = get_logger("MLTasks")

# Rust Core Engine API URL
RUST_API_URL = os.getenv("RUST_API_URL", "http://rust-core-engine:8080")


def fetch_real_candles_sync(symbol: str, timeframe: str = "1h", limit: int = 100) -> pd.DataFrame:
    """
    Fetch REAL candle data from Rust Core Engine API (synchronous version for Celery).

    CRITICAL: This function fetches actual market data from Binance via Rust API.
    Never use dummy/fake data for trading decisions!

    Args:
        symbol: Trading pair symbol (e.g., "BTCUSDT")
        timeframe: Timeframe (e.g., "1h", "4h")
        limit: Number of candles to fetch

    Returns:
        DataFrame with OHLCV data
    """
    try:
        with httpx.Client(timeout=30.0) as client:
            url = f"{RUST_API_URL}/api/market/chart/{symbol}/{timeframe}?limit={limit}"
            logger.info(f"ðŸ“Š Fetching real candles from: {url}")

            response = client.get(url)
            if response.status_code == 200:
                data = response.json()
                candles = data.get("data", {}).get("candles", [])

                if not candles:
                    logger.warning(f"âš ï¸ No candles returned for {symbol}/{timeframe}")
                    return pd.DataFrame()

                df = pd.DataFrame(candles)
                df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms")
                logger.info(f"âœ… Fetched {len(df)} real candles for {symbol}/{timeframe}")
                return df
            else:
                logger.error(f"âŒ Failed to fetch candles: {response.status_code}")
                return pd.DataFrame()

    except Exception as e:
        logger.error(f"âŒ Error fetching real candles for {symbol}: {e}")
        return pd.DataFrame()


def fetch_current_price_sync(symbol: str) -> float:
    """
    Fetch current price from Rust API (synchronous version for Celery).

    Args:
        symbol: Trading pair symbol

    Returns:
        Current price as float, or 0 if failed
    """
    try:
        with httpx.Client(timeout=10.0) as client:
            url = f"{RUST_API_URL}/api/market/prices"
            response = client.get(url)
            if response.status_code == 200:
                prices = response.json()
                return prices.get(symbol, 0)
    except Exception as e:
        logger.error(f"âŒ Error fetching price for {symbol}: {e}")
    return 0


class MLTask(Task):
    """Base task with progress tracking and error handling"""

    def on_failure(self, exc, task_id, args, kwargs, einfo):
        """Log task failure"""
        logger.error(f"Task {task_id} failed: {exc}")
        logger.error(f"Error info: {einfo}")

    def on_success(self, retval, task_id, args, kwargs):
        """Log task success"""
        logger.info(f"Task {task_id} completed successfully")


# @spec:FR-ASYNC-001 - Async ML Model Training
# @ref:specs/01-requirements/1.1-functional-requirements/FR-ASYNC-TASKS.md#fr-async-001
# @test:TC-ASYNC-001, TC-ASYNC-002, TC-ASYNC-003, TC-ASYNC-004, TC-ASYNC-005
@app.task(
    bind=True,
    base=MLTask,
    name="tasks.ml_tasks.train_model",
    max_retries=3,
    default_retry_delay=300,  # 5 minutes
)
def train_model(
    self,
    model_type: str = "lstm",
    symbol: str = "BTCUSDT",
    days_of_data: int = 30,
    retrain: bool = False,
) -> Dict[str, Any]:
    """
    Train ML model asynchronously

    Args:
        model_type: Type of model (lstm, gru, transformer)
        symbol: Trading pair symbol
        days_of_data: Days of historical data to train on
        retrain: Whether to retrain from scratch

    Returns:
        Training results with metrics
    """
    logger.info(f"ðŸš€ Starting async training: {model_type} for {symbol}")

    try:
        # Update task state to show progress
        self.update_state(
            state="PROGRESS",
            meta={
                "current": 0,
                "total": 100,
                "status": f"Initializing {model_type} model...",
            },
        )

        # Initialize model manager
        manager = ModelManager()
        manager.create_model(model_type)

        # Update progress: Data loading
        self.update_state(
            state="PROGRESS",
            meta={
                "current": 20,
                "total": 100,
                "status": f"Loading {days_of_data} days of data for {symbol}...",
            },
        )

        # FIXED: Fetch REAL candle data from Rust API
        # This fetches actual historical market data from Binance
        df = fetch_real_candles_sync(symbol, "1h", days_of_data * 24)

        if df.empty:
            raise ValueError(f"No real market data available for {symbol}. Cannot train on fake data!")

        # Update progress: Training
        self.update_state(
            state="PROGRESS",
            meta={
                "current": 40,
                "total": 100,
                "status": f"Training {model_type} model...",
            },
        )

        # Train model
        training_results = manager.train_model(df, retrain=retrain)

        # Update progress: Complete
        self.update_state(
            state="PROGRESS",
            meta={
                "current": 100,
                "total": 100,
                "status": "Training complete!",
            },
        )

        logger.info(
            f"âœ… Training complete: {model_type} - Accuracy: {training_results.get('val_accuracy', 0):.2%}"
        )

        return {
            "status": "success",
            "model_type": model_type,
            "symbol": symbol,
            "training_results": training_results,
            "task_id": self.request.id,
        }

    except Exception as e:
        logger.error(f"âŒ Training failed: {e}")
        # Retry with exponential backoff
        raise self.retry(exc=e)


# @spec:FR-ASYNC-002 - Batch Symbol Prediction
# @ref:specs/01-requirements/1.1-functional-requirements/FR-ASYNC-TASKS.md#fr-async-002
# @test:TC-ASYNC-011, TC-ASYNC-012, TC-ASYNC-013
@app.task(
    bind=True,
    base=MLTask,
    name="tasks.ml_tasks.bulk_analysis",
)
def bulk_analysis(
    self,
    symbols: List[str],
    timeframe: str = "1h",
) -> Dict[str, Any]:
    """
    Analyze multiple symbols in parallel

    Args:
        symbols: List of trading pair symbols
        timeframe: Timeframe for analysis

    Returns:
        Analysis results for all symbols
    """
    logger.info(f"ðŸ” Starting bulk analysis for {len(symbols)} symbols")

    results = {}
    total = len(symbols)

    for i, symbol in enumerate(symbols):
        # Update progress
        self.update_state(
            state="PROGRESS",
            meta={
                "current": i + 1,
                "total": total,
                "status": f"Analyzing {symbol}...",
                "completed_symbols": list(results.keys()),
            },
        )

        try:
            # FIXED: Fetch REAL candle data and calculate REAL indicators
            df = fetch_real_candles_sync(symbol, timeframe, 100)
            current_price = fetch_current_price_sync(symbol)

            if df.empty or current_price == 0:
                results[symbol] = {"error": f"No real data available for {symbol}"}
                continue

            # Calculate REAL technical indicators from actual market data
            close_prices = df["close"].values

            # RSI calculation (14 period)
            delta = np.diff(close_prices)
            gains = np.where(delta > 0, delta, 0)
            losses = np.where(delta < 0, -delta, 0)
            avg_gain = np.mean(gains[-14:]) if len(gains) >= 14 else np.mean(gains)
            avg_loss = np.mean(losses[-14:]) if len(losses) >= 14 else np.mean(losses)
            rs = avg_gain / avg_loss if avg_loss != 0 else 100
            rsi = 100 - (100 / (1 + rs))

            # MACD calculation (12, 26, 9)
            ema_12 = pd.Series(close_prices).ewm(span=12).mean().iloc[-1]
            ema_26 = pd.Series(close_prices).ewm(span=26).mean().iloc[-1]
            macd = ema_12 - ema_26

            # Determine signal based on REAL indicators
            if rsi < 30 and macd > 0:
                signal = "BUY"
                confidence = min(0.85, 0.5 + (30 - rsi) / 100 + abs(macd) / 1000)
            elif rsi > 70 and macd < 0:
                signal = "SELL"
                confidence = min(0.85, 0.5 + (rsi - 70) / 100 + abs(macd) / 1000)
            else:
                signal = "HOLD"
                confidence = 0.5

            results[symbol] = {
                "signal": signal,
                "confidence": round(confidence, 3),
                "price": current_price,
                "indicators": {
                    "rsi": round(rsi, 2),
                    "macd": round(macd, 4),
                },
            }

        except Exception as e:
            logger.error(f"âŒ Analysis failed for {symbol}: {e}")
            results[symbol] = {"error": str(e)}

    logger.info(f"âœ… Bulk analysis complete: {len(results)}/{total} symbols")

    return {
        "status": "success",
        "symbols_analyzed": len(results),
        "results": results,
        "task_id": self.request.id,
    }


# @spec:FR-ASYNC-003 - Model Evaluation
# @ref:specs/01-requirements/1.1-functional-requirements/FR-ASYNC-TASKS.md#fr-async-003
# @test:TC-ASYNC-016, TC-ASYNC-017, TC-ASYNC-018
@app.task(
    bind=True,
    base=MLTask,
    name="tasks.ml_tasks.predict_price",
)
def predict_price(
    self,
    symbol: str,
    model_type: str = "lstm",
    horizon_hours: int = 24,
) -> Dict[str, Any]:
    """
    Predict future price using trained ML model

    Args:
        symbol: Trading pair symbol
        model_type: Model to use for prediction
        horizon_hours: Prediction horizon in hours

    Returns:
        Price predictions
    """
    logger.info(
        f"ðŸ“Š Predicting {symbol} price for next {horizon_hours} hours using {model_type}"
    )

    try:
        # FIXED: Fetch REAL current price and historical data for trend-based predictions
        current_price = fetch_current_price_sync(symbol)
        df = fetch_real_candles_sync(symbol, "1h", 100)

        if current_price == 0 or df.empty:
            raise ValueError(f"No real market data available for {symbol}. Cannot make predictions without real data!")

        # Calculate trend from real historical data
        close_prices = df["close"].values
        recent_prices = close_prices[-24:] if len(close_prices) >= 24 else close_prices

        # Calculate average hourly change from real data
        price_changes = np.diff(recent_prices) / recent_prices[:-1]
        avg_change = np.mean(price_changes) if len(price_changes) > 0 else 0
        volatility = np.std(price_changes) if len(price_changes) > 0 else 0.01

        # Generate predictions based on real trend (not random!)
        predictions = []
        pred_price = current_price

        for h in range(horizon_hours):
            # Trend-based prediction with decreasing confidence over time
            # Use actual trend, not random values
            pred_price *= 1 + avg_change
            confidence = max(0.3, 0.85 - (h * 0.02) - (volatility * 10))

            predictions.append(
                {
                    "hour": h + 1,
                    "predicted_price": round(pred_price, 2),
                    "confidence": round(confidence, 3),
                    "trend_direction": "UP" if avg_change > 0 else "DOWN" if avg_change < 0 else "FLAT",
                }
            )

        logger.info(f"âœ… Prediction complete: {symbol} (current: ${current_price:.2f}, trend: {avg_change*100:.2f}%/hr)")

        return {
            "status": "success",
            "symbol": symbol,
            "model_type": model_type,
            "horizon_hours": horizon_hours,
            "predictions": predictions,
            "task_id": self.request.id,
        }

    except Exception as e:
        logger.error(f"âŒ Prediction failed: {e}")
        raise
