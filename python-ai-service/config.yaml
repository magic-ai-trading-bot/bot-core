server:
  host: "0.0.0.0"
  port: 8000
  reload: false

model:
  type: "lstm" # lstm, gru, or transformer
  sequence_length: 60
  features_count: 15
  hidden_size: 64
  num_layers: 2
  dropout: 0.2
  learning_rate: 0.001
  batch_size: 32
  epochs: 100
  validation_split: 0.2

trading:
  long_threshold: 0.55
  short_threshold: 0.45
  neutral_zone: 0.1
  confidence_threshold: 0.45

technical_indicators:
  rsi_period: 14
  macd_fast: 12
  macd_slow: 26
  macd_signal: 9
  ema_periods: [9, 21, 50]
  bollinger_period: 20
  bollinger_std: 2
  volume_sma_period: 20

data:
  supported_timeframes: ["1m", "5m", "15m", "1h", "4h", "1d"]
  min_candles_required: 100
  max_candles_per_request: 1000

ai_cache:
  enabled: true
  duration_minutes: 2 # Cache AI analysis for 2 minutes (reduced from 15 for fresh trading signals)
  max_entries: 100 # Maximum number of cache entries

# Signal generation config (UNIFIED for both GPT-4 and fallback)
# These values are used by both GPT-4 prompt and fallback technical analysis
# to ensure consistent signal generation regardless of which method is used
signal:
  trend_threshold_percent: 0.8  # Trend must exceed this % to count as bullish/bearish
                                # Lower = more signals, Higher = more conservative
  min_required_timeframes: 3    # Out of 4 timeframes (15M, 30M, 1H, 4H)
                                # 3 = 75% agreement required
                                # 2 = 50% agreement (more aggressive)
  confidence_base: 0.5          # Base confidence when signal is triggered
  confidence_per_timeframe: 0.08 # Add this per agreeing timeframe (max ~0.82 with 4TF)

model_management:
  model_save_path: "./models/saved/"
  retrain_interval_hours: 24
  backup_count: 5
  auto_retrain: true

logging:
  level: "INFO"
  format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{function}:{line} | {message}"
  file: "./logs/trading_ai.log"
  rotation: "10 MB"
  retention: "7 days"
