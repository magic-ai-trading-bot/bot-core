"""
Project Chatbot Service with RAG (Retrieval Augmented Generation)
Answers questions about the BotCore trading project using project documentation.
"""

import os
import re
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timezone
import asyncio

logger = logging.getLogger(__name__)


# Project root directory - try multiple locations
def _find_project_root() -> Path:
    """Find the project root directory."""
    # Try relative to this file (local development)
    local_root = Path(__file__).parent.parent.parent
    if (local_root / "CLAUDE.md").exists():
        return local_root

    # Try Docker mounted volume paths
    docker_paths = [
        Path("/project"),  # Docker mounted project docs
        Path("/app"),  # If mounted at /app
        Path("/workspace"),  # If mounted at /workspace
        Path("/bot-core"),  # If mounted at /bot-core
    ]
    for docker_path in docker_paths:
        if (docker_path / "CLAUDE.md").exists():
            return docker_path

    # Try environment variable
    env_root = os.getenv("PROJECT_ROOT")
    if env_root and Path(env_root).exists():
        return Path(env_root)

    # Fallback: search upward from current working directory
    cwd = Path.cwd()
    for parent in [cwd] + list(cwd.parents):
        if (parent / "CLAUDE.md").exists():
            return parent

    # Last resort: return local_root anyway
    logger.warning(f"Could not find project root with CLAUDE.md, using: {local_root}")
    return local_root


PROJECT_ROOT = _find_project_root()
logger.info(f"ğŸ“ Project root: {PROJECT_ROOT}")


class DocumentIndex:
    """Simple in-memory document index for RAG."""

    def __init__(self):
        self.documents: List[Dict[str, Any]] = []
        self.indexed = False

    def add_document(self, path: str, content: str, doc_type: str, title: str = ""):
        """Add a document to the index."""
        # Split into chunks for better retrieval
        chunks = self._chunk_content(content, chunk_size=1500, overlap=200)

        for i, chunk in enumerate(chunks):
            self.documents.append(
                {
                    "path": path,
                    "content": chunk,
                    "doc_type": doc_type,
                    "title": title or Path(path).stem,
                    "chunk_index": i,
                    "total_chunks": len(chunks),
                }
            )

    def _chunk_content(
        self, content: str, chunk_size: int = 1500, overlap: int = 200
    ) -> List[str]:
        """Split content into overlapping chunks."""
        if len(content) <= chunk_size:
            return [content]

        chunks = []
        start = 0
        while start < len(content):
            end = start + chunk_size
            chunk = content[start:end]

            # Try to break at paragraph or sentence boundary
            if end < len(content):
                # Look for paragraph break
                last_para = chunk.rfind("\n\n")
                if last_para > chunk_size * 0.5:
                    chunk = chunk[:last_para]
                    end = start + last_para
                else:
                    # Look for sentence break
                    last_sentence = max(chunk.rfind(". "), chunk.rfind(".\n"))
                    if last_sentence > chunk_size * 0.5:
                        chunk = chunk[: last_sentence + 1]
                        end = start + last_sentence + 1

            chunks.append(chunk.strip())
            start = end - overlap

        return chunks

    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """Enhanced keyword-based search with Vietnamese support."""
        query_lower = query.lower()
        query_terms = set(query_lower.split())

        # Expand terms with synonyms and variations
        expanded_terms = set()
        synonym_map = {
            "báº£o máº­t": ["security", "báº£o máº­t", "bao mat", "secure"],
            "lá»›p": ["layer", "lá»›p", "lop", "layers", "táº§ng"],
            "rá»§i ro": ["risk", "rá»§i ro", "rui ro"],
            "chiáº¿n lÆ°á»£c": ["strategy", "chiáº¿n lÆ°á»£c", "chien luoc", "strategies"],
            "giao dá»‹ch": ["trading", "giao dá»‹ch", "giao dich", "trade"],
            "hoáº¡t Ä‘á»™ng": ["work", "hoáº¡t Ä‘á»™ng", "hoat dong", "working", "how"],
            "cáº¥u hÃ¬nh": ["config", "cáº¥u hÃ¬nh", "cau hinh", "configuration", "setup"],
            "paper": ["paper", "giáº£ láº­p", "gia lap", "simulation"],
            "7": ["7", "báº£y", "bay", "seven"],
        }

        for term in query_terms:
            expanded_terms.add(term)
            # Check if term matches any synonym key or value
            for key, synonyms in synonym_map.items():
                if term in key.lower() or any(term in s.lower() for s in synonyms):
                    expanded_terms.update(synonyms)
                    expanded_terms.add(key)

        # Extract numbers from query
        import re

        numbers = re.findall(r"\d+", query)
        expanded_terms.update(numbers)

        scored_docs = []
        for doc in self.documents:
            content_lower = doc["content"].lower()
            title_lower = doc["title"].lower()
            path_lower = doc["path"].lower()

            # Calculate relevance score
            score = 0

            # Exact phrase matching (highest priority)
            if query_lower in content_lower:
                score += 20
            if query_lower in title_lower:
                score += 30

            for term in expanded_terms:
                # Title match is worth more
                if term in title_lower:
                    score += 8
                # Path match (file name relevance)
                if term in path_lower:
                    score += 5
                # Content matches
                count = content_lower.count(term)
                score += min(count, 10)  # Cap at 10 per term

            # Boost certain doc types for certain queries
            if any(t in query_lower for t in ["api", "endpoint", "request"]):
                if "api" in doc["doc_type"].lower():
                    score += 5
            if any(
                t in query_lower
                for t in ["how", "lÃ m sao", "cÃ¡ch", "hÆ°á»›ng dáº«n", "giáº£i thÃ­ch"]
            ):
                if "feature" in doc["doc_type"].lower() or "readme" in path_lower:
                    score += 5
            if any(
                t in query_lower
                for t in ["báº£o máº­t", "security", "risk", "rá»§i ro", "lá»›p", "layer"]
            ):
                if (
                    "risk" in path_lower
                    or "security" in path_lower
                    or "layer" in path_lower
                ):
                    score += 10
                if "report" in doc["doc_type"].lower():
                    score += 5

            if score > 0:
                scored_docs.append((score, doc))

        # Sort by score and return top_k
        scored_docs.sort(key=lambda x: x[0], reverse=True)
        return [doc for _, doc in scored_docs[:top_k]]


class ProjectChatbot:
    """RAG-based chatbot for answering questions about the BotCore project."""

    def __init__(self, openai_client=None):
        self.openai_client = openai_client
        self.index = DocumentIndex()
        self.conversation_history: List[Dict[str, str]] = []
        self._indexed = False

    async def initialize(self):
        """Initialize the chatbot by indexing project documents."""
        if self._indexed:
            return

        logger.info("ğŸ“š Indexing project documentation...")
        await self._index_documents()
        self._indexed = True
        logger.info(f"âœ… Indexed {len(self.index.documents)} document chunks")

    async def _index_documents(self):
        """Index all relevant project documents."""
        # Key documentation paths to index
        doc_paths = [
            # Main documentation
            ("docs/features", "feature"),
            ("docs/reports", "report"),
            ("docs/guides", "guide"),
            ("docs/plans", "plan"),
            ("specs/01-requirements/1.1-functional-requirements", "requirement"),
            ("specs/02-design/2.3-api", "api"),
            ("specs/02-design/2.5-components", "component"),
            ("docs", "guide"),
        ]

        # Also index CLAUDE.md for project overview
        claude_md = PROJECT_ROOT / "CLAUDE.md"
        if claude_md.exists():
            content = claude_md.read_text(encoding="utf-8")
            self.index.add_document(
                str(claude_md), content, "overview", "Project Overview (CLAUDE.md)"
            )

        # Index README files
        for readme in [
            "README.md",
            "nextjs-ui-dashboard/README.md",
            "rust-core-engine/README.md",
        ]:
            readme_path = PROJECT_ROOT / readme
            if readme_path.exists():
                content = readme_path.read_text(encoding="utf-8")
                self.index.add_document(str(readme_path), content, "readme", readme)

        # Index documentation directories
        for path_str, doc_type in doc_paths:
            dir_path = PROJECT_ROOT / path_str
            if not dir_path.exists():
                continue

            for md_file in dir_path.glob("**/*.md"):
                try:
                    content = md_file.read_text(encoding="utf-8")
                    relative_path = str(md_file.relative_to(PROJECT_ROOT))
                    self.index.add_document(
                        relative_path, content, doc_type, md_file.stem
                    )
                except Exception as e:
                    logger.warning(f"Failed to index {md_file}: {e}")

        self.index.indexed = True

    def _build_context(self, relevant_docs: List[Dict[str, Any]]) -> str:
        """Build context string from relevant documents."""
        if not relevant_docs:
            return "KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u liÃªn quan."

        context_parts = []
        for doc in relevant_docs:
            header = f"ğŸ“„ {doc['title']} ({doc['doc_type']})"
            context_parts.append(f"{header}\n{doc['content']}")

        return "\n\n---\n\n".join(context_parts)

    def _get_system_prompt(self) -> str:
        """Get system prompt for the chatbot."""
        return """Báº¡n lÃ  AI Assistant cá»§a BotCore - má»™t ná»n táº£ng giao dá»‹ch cryptocurrency AI-powered.

THÃ”NG TIN Vá»€ BOTCORE:
- BotCore lÃ  há»‡ thá»‘ng trading bot sá»­ dá»¥ng AI (GPT-4, ML models) Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  giao dá»‹ch crypto futures
- 3 services chÃ­nh: Rust Core Engine (trading), Python AI Service (ML/AI), Next.js Dashboard (UI)
- Há»— trá»£ 4 chiáº¿n lÆ°á»£c: RSI, MACD, Bollinger Bands, Volume Analysis
- Paper Trading mode Ä‘á»ƒ test trÆ°á»›c khi trade tháº­t
- Real-time WebSocket Ä‘á»ƒ cáº­p nháº­t giÃ¡ vÃ  signals

HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
1. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n vÃ  dá»… hiá»ƒu
2. Sá»­ dá»¥ng thÃ´ng tin tá»« CONTEXT Ä‘Æ°á»£c cung cáº¥p
3. Náº¿u khÃ´ng tÃ¬m tháº¥y trong context, nÃ³i rÃµ vÃ  Ä‘Æ°a ra cÃ¢u tráº£ lá»i chung
4. Format vá»›i bullet points vÃ  emoji khi phÃ¹ há»£p
5. Náº¿u lÃ  cÃ¢u há»i ká»¹ thuáº­t, Ä‘Æ°a ra code example hoáº·c config example
6. LuÃ´n cáº£nh bÃ¡o vá» rá»§i ro khi nÃ³i vá» trading tháº­t

KHÃ”NG ÄÆ¯á»¢C:
- ÄÆ°a ra lá»i khuyÃªn tÃ i chÃ­nh cá»¥ thá»ƒ
- Há»©a háº¹n vá» lá»£i nhuáº­n
- Khuyáº¿n khÃ­ch trade vá»›i sá»‘ tiá»n lá»›n"""

    async def chat(self, message: str, include_history: bool = True) -> Dict[str, Any]:
        """Process a chat message and return response."""
        if not self._indexed:
            await self.initialize()

        # Search for relevant documents
        relevant_docs = self.index.search(message, top_k=5)
        context = self._build_context(relevant_docs)

        # Build messages for GPT
        messages = [{"role": "system", "content": self._get_system_prompt()}]

        # Add conversation history (last 6 messages)
        if include_history and self.conversation_history:
            messages.extend(self.conversation_history[-6:])

        # Add context and user message
        user_content = f"""CONTEXT Tá»ª TÃ€I LIá»†U Dá»° ÃN:
{context}

---

CÃ‚U Há»I Cá»¦A USER:
{message}"""

        messages.append({"role": "user", "content": user_content})

        # Call GPT if available
        if self.openai_client:
            try:
                response = await self.openai_client.chat_completions_create(
                    model="gpt-5-mini",
                    messages=messages,
                    max_tokens=1000,
                    temperature=0.7,
                )

                assistant_message = response["choices"][0]["message"]["content"]

                # Update conversation history
                self.conversation_history.append({"role": "user", "content": message})
                self.conversation_history.append(
                    {"role": "assistant", "content": assistant_message}
                )

                # Keep history limited
                if len(self.conversation_history) > 20:
                    self.conversation_history = self.conversation_history[-20:]

                return {
                    "success": True,
                    "message": assistant_message,
                    "sources": [
                        {"title": doc["title"], "path": doc["path"]}
                        for doc in relevant_docs[:3]
                    ],
                    "confidence": 0.9 if relevant_docs else 0.6,
                    "type": "rag",
                    "tokens_used": response.get("usage", {}),
                }

            except Exception as e:
                logger.error(f"GPT-4 error: {e}")
                return await self._fallback_response(message, relevant_docs)
        else:
            return await self._fallback_response(message, relevant_docs)

    async def _fallback_response(
        self, message: str, relevant_docs: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Fallback response when GPT is not available."""
        # Simple keyword-based responses
        message_lower = message.lower()

        response = ""

        if any(word in message_lower for word in ["hoáº¡t Ä‘á»™ng", "lÃ m viá»‡c", "work"]):
            response = """ğŸ¤– **BotCore hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o:**

1. **Thu tháº­p dá»¯ liá»‡u**: Káº¿t ná»‘i Binance API Ä‘á»ƒ láº¥y giÃ¡ real-time
2. **PhÃ¢n tÃ­ch AI**:
   - GPT-4 phÃ¢n tÃ­ch sentiment vÃ  xu hÆ°á»›ng
   - ML models (LSTM, GRU) dá»± Ä‘oÃ¡n giÃ¡
3. **Táº¡o signals**: Káº¿t há»£p RSI, MACD, Bollinger Bands, Volume
4. **Thá»±c thi lá»‡nh**: Auto trade hoáº·c thÃ´ng bÃ¡o Ä‘á»ƒ báº¡n quyáº¿t Ä‘á»‹nh
5. **Quáº£n lÃ½ rá»§i ro**: Stop-loss, take-profit, position sizing

ğŸ’¡ KhuyÃªn dÃ¹ng Paper Trading Ä‘á»ƒ test trÆ°á»›c!"""

        elif any(
            word in message_lower for word in ["báº¯t Ä‘áº§u", "start", "setup", "cÃ i Ä‘áº·t"]
        ):
            response = """ğŸš€ **Báº¯t Ä‘áº§u vá»›i BotCore:**

1. **Clone repo vÃ  setup:**
   ```bash
   git clone <repo>
   cp .env.example .env
   ./scripts/generate-secrets.sh
   ```

2. **Cáº¥u hÃ¬nh API keys:**
   - Táº¡o Binance API key (chá»‰ cáº§n quyá»n trade)
   - ThÃªm OpenAI API key cho AI features

3. **Cháº¡y services:**
   ```bash
   ./scripts/bot.sh start --memory-optimized
   ```

4. **Truy cáº­p Dashboard:** http://localhost:3000

âš ï¸ Báº¯t Ä‘áº§u vá»›i Paper Trading mode Ä‘á»ƒ lÃ m quen!"""

        elif any(
            word in message_lower for word in ["chiáº¿n lÆ°á»£c", "strategy", "rsi", "macd"]
        ):
            response = """ğŸ“Š **CÃ¡c chiáº¿n lÆ°á»£c trading cá»§a BotCore:**

1. **RSI Strategy** (Win rate: 62%)
   - Mua khi RSI < 30, bÃ¡n khi RSI > 70
   - Timeframe: 15m, 1h

2. **MACD Strategy** (Win rate: 58%)
   - Theo dÃµi MACD crossover
   - Káº¿t há»£p histogram divergence

3. **Bollinger Bands** (Win rate: 60%)
   - Trade breakout vÃ  mean reversion
   - Káº¿t há»£p vá»›i volume

4. **Volume Strategy** (Win rate: 52%)
   - PhÃ¡t hiá»‡n volume spike
   - XÃ¡c nháº­n trend strength

ğŸ’¡ CÃ³ thá»ƒ báº­t/táº¯t tá»«ng strategy trong Settings"""

        elif any(
            word in message_lower for word in ["an toÃ n", "báº£o máº­t", "security", "risk"]
        ):
            response = """ğŸ”’ **Báº£o máº­t & Quáº£n lÃ½ rá»§i ro:**

**Báº£o máº­t:**
- API keys mÃ£ hÃ³a AES-256
- Tiá»n luÃ´n trong tÃ i khoáº£n Binance cá»§a báº¡n
- Bot khÃ´ng cÃ³ quyá»n rÃºt tiá»n
- JWT authentication cho dashboard

**Quáº£n lÃ½ rá»§i ro:**
- Stop-loss tá»± Ä‘á»™ng (1-15%)
- Take-profit Ä‘á»ƒ chá»‘t lá»i
- Daily loss limit (5% max)
- Cool-down sau 5 losses liÃªn tiáº¿p
- Position sizing theo % balance

âš ï¸ **Quan trá»ng:** Chá»‰ trade vá»›i sá»‘ tiá»n báº¡n cÃ³ thá»ƒ máº¥t!"""

        else:
            # Return relevant docs content as fallback
            if relevant_docs:
                response = f"""ğŸ“š Dá»±a trÃªn tÃ i liá»‡u dá»± Ã¡n:

{relevant_docs[0]['content'][:800]}...

ğŸ’¡ Báº¡n cÃ³ thá»ƒ há»i cá»¥ thá»ƒ hÆ¡n Ä‘á»ƒ tÃ´i tráº£ lá»i chÃ­nh xÃ¡c hÆ¡n!"""
            else:
                response = """ğŸ¤” TÃ´i chÆ°a tÃ¬m tháº¥y thÃ´ng tin cá»¥ thá»ƒ vá» cÃ¢u há»i nÃ y trong tÃ i liá»‡u.

Báº¡n cÃ³ thá»ƒ há»i vá»:
â€¢ Bot hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?
â€¢ CÃ¡ch báº¯t Ä‘áº§u sá»­ dá»¥ng?
â€¢ CÃ¡c chiáº¿n lÆ°á»£c trading?
â€¢ Báº£o máº­t vÃ  quáº£n lÃ½ rá»§i ro?
â€¢ Cáº¥u hÃ¬nh API keys?

Hoáº·c liÃªn há»‡ support Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ trá»±c tiáº¿p!"""

        return {
            "success": True,
            "message": response,
            "sources": [
                {"title": doc["title"], "path": doc["path"]}
                for doc in relevant_docs[:3]
            ],
            "confidence": 0.7 if relevant_docs else 0.5,
            "type": "fallback",
        }

    def clear_history(self):
        """Clear conversation history."""
        self.conversation_history = []

    def get_suggested_questions(self) -> List[str]:
        """Get suggested questions for users."""
        return [
            "Bot hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?",
            "LÃ m sao Ä‘á»ƒ báº¯t Ä‘áº§u sá»­ dá»¥ng?",
            "CÃ¡c chiáº¿n lÆ°á»£c trading lÃ  gÃ¬?",
            "Bot cÃ³ an toÃ n khÃ´ng?",
            "Vá»‘n tá»‘i thiá»ƒu lÃ  bao nhiÃªu?",
            "CÃ¡ch cáº¥u hÃ¬nh API keys?",
            "Paper trading lÃ  gÃ¬?",
            "CÃ¡ch xem káº¿t quáº£ trading?",
        ]


# Singleton instance
_chatbot_instance: Optional[ProjectChatbot] = None


async def get_chatbot(openai_client=None) -> ProjectChatbot:
    """Get or create chatbot instance."""
    global _chatbot_instance

    if _chatbot_instance is None:
        _chatbot_instance = ProjectChatbot(openai_client)
        await _chatbot_instance.initialize()
    elif openai_client and _chatbot_instance.openai_client is None:
        _chatbot_instance.openai_client = openai_client

    return _chatbot_instance
