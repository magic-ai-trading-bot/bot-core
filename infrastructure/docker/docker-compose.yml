services:
  # Python AI Service
  python-ai-service:
    build:
      context: ./python-ai-service
      dockerfile: ${DOCKERFILE:-Dockerfile}
    container_name: python-ai-service
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - INTER_SERVICE_TOKEN=${INTER_SERVICE_TOKEN:-default_inter_service_token}
      - PYTHON_API_KEY=${PYTHON_API_KEY:-default_python_api_key}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DATABASE_URL=${DATABASE_URL:-mongodb://admin:secure_mongo_password_change_me@mongodb:27017/bot_core?authSource=admin}
      - RUST_API_URL=http://rust-core-engine:8080
    volumes:
      - ./python-ai-service/models:/app/models
      - ./python-ai-service/logs:/app/logs
      - ./python-ai-service/data:/app/data
      - ./python-ai-service/config.yaml:/app/config.yaml
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: ${PYTHON_MEMORY_LIMIT:-2G}
          cpus: "${PYTHON_CPU_LIMIT:-2}"
        reservations:
          memory: ${PYTHON_MEMORY_RESERVE:-1G}
          cpus: "${PYTHON_CPU_RESERVE:-1}"
    profiles:
      - prod

  # Python AI Service - Development mode
  python-ai-service-dev:
    build:
      context: ./python-ai-service
      dockerfile: Dockerfile.dev
      target: development
    container_name: python-ai-service-dev
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - LOG_LEVEL=DEBUG
      - FLASK_ENV=development
      - ENABLE_HOT_RELOAD=true
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DATABASE_URL=${DATABASE_URL}
      - RUST_API_URL=http://rust-core-engine-dev:8080
    volumes:
      - ./python-ai-service:/app
      - /app/__pycache__
      - /app/models/saved
      # Mount project docs for RAG chatbot
      - ./docs:/project/docs:ro
      - ./specs:/project/specs:ro
      - ./CLAUDE.md:/project/CLAUDE.md:ro
      - ./README.md:/project/README.md:ro
    command:
      [
        "python",
        "-m",
        "uvicorn",
        "main:app",
        "--host",
        "0.0.0.0",
        "--port",
        "8000",
        "--reload",
      ]
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "--max-time", "10", "http://localhost:8000/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: "1.5"
    profiles:
      - dev

  # Rust Core Engine
  rust-core-engine:
    build:
      context: ./rust-core-engine
      dockerfile: ${DOCKERFILE:-Dockerfile}
    container_name: rust-core-engine
    restart: unless-stopped
    ports:
      - "8080:8080"
    environment:
      - RUST_LOG=${RUST_LOG:-info}
      - DATABASE_URL=${DATABASE_URL:-mongodb://admin:secure_mongo_password_change_me@mongodb:27017/bot_core?authSource=admin}
      - PYTHON_AI_SERVICE_URL=http://python-ai-service:8000
      - BINANCE_API_KEY=${BINANCE_API_KEY:-default_binance_api_key}
      - BINANCE_SECRET_KEY=${BINANCE_SECRET_KEY:-default_binance_secret}
      - BINANCE_TESTNET=${BINANCE_TESTNET:-true}
      - TRADING_ENABLED=${TRADING_ENABLED:-false}
      - INTER_SERVICE_TOKEN=${INTER_SERVICE_TOKEN:-default_inter_service_token}
      - RUST_API_KEY=${RUST_API_KEY:-default_rust_api_key}
    volumes:
      - ./rust-core-engine/data:/app/data
      - ./rust-core-engine/logs:/app/logs
      - ./rust-core-engine/config.toml:/app/config.toml
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      python-ai-service:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: ${RUST_MEMORY_LIMIT:-2G}
          cpus: "${RUST_CPU_LIMIT:-2}"
        reservations:
          memory: ${RUST_MEMORY_RESERVE:-1G}
          cpus: "${RUST_CPU_RESERVE:-1}"
    profiles:
      - prod

  # Rust Core Engine - Development mode
  rust-core-engine-dev:
    build:
      context: ./rust-core-engine
      dockerfile: Dockerfile.dev
    container_name: rust-core-engine-dev
    restart: unless-stopped
    ports:
      - "8080:8080"
    environment:
      - RUST_LOG=debug
      - RUST_BACKTRACE=1
      - DATABASE_URL=${DATABASE_URL:-mongodb://admin:secure_mongo_password_change_me@mongodb:27017/bot_core?authSource=admin}
      - PYTHON_AI_SERVICE_URL=http://python-ai-service-dev:8000
      - BINANCE_API_KEY=${BINANCE_API_KEY:-default_binance_api_key}
      - BINANCE_SECRET_KEY=${BINANCE_SECRET_KEY:-default_binance_secret}
      # CRITICAL: Use production API (false) for paper trading to get REAL prices
      # Paper trading is safe with production API - it only reads prices, never trades
      # TESTNET is unreliable and causes stop-loss to fail
      - BINANCE_TESTNET=${BINANCE_TESTNET:-false}
      - TRADING_ENABLED=${TRADING_ENABLED:-false}
      - INTER_SERVICE_TOKEN=${INTER_SERVICE_TOKEN:-default_inter_service_token}
      - RUST_API_KEY=${RUST_API_KEY:-default_rust_api_key}
    volumes:
      - ./rust-core-engine/src:/app/src
      - ./rust-core-engine/Cargo.toml:/app/Cargo.toml
      - ./rust-core-engine/Cargo.lock:/app/Cargo.lock
      - ./rust-core-engine/config.toml:/app/config.toml
      - ./rust-core-engine/data:/app/data
      - ./rust-core-engine/logs:/app/logs
      - rust_target_cache:/app/target
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "--max-time", "10", "http://localhost:8080/api/health"]
      interval: 30s
      timeout: 15s
      retries: 10
      start_period: 300s
    depends_on:
      python-ai-service-dev:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: "1.5"
    profiles:
      - dev

  # Next.js UI Dashboard
  nextjs-ui-dashboard:
    build:
      context: ./nextjs-ui-dashboard
      dockerfile: ${DOCKERFILE:-Dockerfile}
    container_name: nextjs-ui-dashboard
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=${NODE_ENV:-production}
      - VITE_RUST_API_URL=http://rust-core-engine:8080
      - VITE_PYTHON_AI_URL=http://python-ai-service:8000
      - VITE_WS_URL=ws://rust-core-engine:8080/ws
      - VITE_API_TIMEOUT=10000
      - VITE_REFRESH_INTERVAL=5000
      - VITE_ENABLE_REALTIME=true
      - DASHBOARD_SESSION_SECRET=${DASHBOARD_SESSION_SECRET:-default_dashboard_session_secret}
      - NODE_OPTIONS="--max-old-space-size=${NODE_MEMORY:-1024}"
    # No volumes needed for production static serving
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    depends_on:
      - rust-core-engine
      - python-ai-service
    deploy:
      resources:
        limits:
          memory: ${FRONTEND_MEMORY_LIMIT:-1G}
          cpus: "${FRONTEND_CPU_LIMIT:-1}"
        reservations:
          memory: ${FRONTEND_MEMORY_RESERVE:-256M}
          cpus: "${FRONTEND_CPU_RESERVE:-0.5}"
    profiles:
      - prod

  # Frontend Development mode
  nextjs-ui-dashboard-dev:
    build:
      context: ./nextjs-ui-dashboard
      dockerfile: Dockerfile.dev
      target: development
    container_name: nextjs-ui-dashboard-dev
    restart: unless-stopped
    ports:
      - "3000:3000"
      - "24678:24678" # HMR WebSocket port
    environment:
      - NODE_ENV=development
      - VITE_RUST_API_URL=http://localhost:8080
      - VITE_PYTHON_AI_URL=http://localhost:8000
      - VITE_WS_URL=ws://localhost:8080/ws
      - VITE_API_TIMEOUT=10000
      - VITE_REFRESH_INTERVAL=5000
      - VITE_ENABLE_REALTIME=true
      - CHOKIDAR_USEPOLLING=true
      - NODE_OPTIONS="--max-old-space-size=768"
      # Vite HMR configuration
      - HMR_PORT=24678
      # Bun compatibility flags
      - BUN_RUNTIME_TRANSPILER_CACHE_PATH=/tmp/bun-cache
      # Enable Bun optimizations but keep WebSocket working
      - BUN_ENABLE_JEMALLOC=true
      - BUN_ENABLE_SMOL=false
    volumes:
      - ./nextjs-ui-dashboard/src:/app/src:delegated
      - ./nextjs-ui-dashboard/public:/app/public:delegated
      - ./nextjs-ui-dashboard/index.html:/app/index.html:ro
      - ./nextjs-ui-dashboard/vite.config.ts:/app/vite.config.ts:ro
      - ./nextjs-ui-dashboard/tailwind.config.ts:/app/tailwind.config.ts:ro
    command: ["bun", "run", "dev", "--", "--host", "0.0.0.0", "--port", "3000"]
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    depends_on:
      - python-ai-service-dev
      - rust-core-engine-dev
    deploy:
      resources:
        limits:
          memory: 768M
          cpus: "1"
    profiles:
      - dev


  # MongoDB - Primary database (standalone for local development)
  mongodb:
    image: mongo:7.0
    container_name: mongodb
    restart: unless-stopped
    command: ["--bind_ip_all", "--port", "27017"]
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_ROOT_USER:-admin}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_ROOT_PASSWORD:-secure_mongo_password_change_me}
      - MONGO_INITDB_DATABASE=bot_core
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
      - mongodb_config:/data/configdb
      - ./infrastructure/docker/scripts/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - bot-network
    healthcheck:
      test: |
        mongosh --quiet --eval "
          try {
            db.adminCommand('ping');
            print('MongoDB is healthy');
          } catch (err) {
            print('MongoDB is not ready');
            quit(1);
          }
        " || exit 1
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: ${MONGO_MEMORY_LIMIT:-2G}
          cpus: "${MONGO_CPU_LIMIT:-2}"
        reservations:
          memory: ${MONGO_MEMORY_RESERVE:-512M}
          cpus: "${MONGO_CPU_RESERVE:-0.5}"

  # MongoDB Express - Web-based admin interface (optional)
  mongo-express:
    image: mongo-express:1.0-20
    container_name: mongo-express
    restart: unless-stopped
    ports:
      - "8081:8081"
    environment:
      - ME_CONFIG_MONGODB_ADMINUSERNAME=${MONGO_ROOT_USER:-admin}
      - ME_CONFIG_MONGODB_ADMINPASSWORD=${MONGO_ROOT_PASSWORD:-secure_mongo_password_change_me}
      - ME_CONFIG_MONGODB_URL=mongodb://${MONGO_ROOT_USER:-admin}:${MONGO_ROOT_PASSWORD:-secure_mongo_password_change_me}@mongodb:27017/
      - ME_CONFIG_BASICAUTH_USERNAME=${MONGO_EXPRESS_USER:-admin}
      - ME_CONFIG_BASICAUTH_PASSWORD=${MONGO_EXPRESS_PASSWORD:-admin}
    depends_on:
      mongodb:
        condition: service_healthy
    networks:
      - bot-network
    profiles:
      - mongo-admin

  # Redis service - For caching and session management
  redis:
    image: redis:7-alpine
    container_name: redis-cache
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-redis_default_password}
    volumes:
      - redis_data:/data
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    profiles:
      - messaging
      - redis

  # RabbitMQ service - Message queue for async processing
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: rabbitmq
    restart: unless-stopped
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER:-admin}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD:-rabbitmq_default_password}
      - RABBITMQ_DEFAULT_VHOST=bot-core
    ports:
      - "5672:5672"   # AMQP port
      - "15672:15672" # Management UI
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - ./infrastructure/rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
      # DISABLED: definitions.json has hardcoded password hash that conflicts with .env
      # Exchanges/queues will be auto-created by Celery on first connection
      # - ./infrastructure/rabbitmq/definitions.json:/etc/rabbitmq/definitions.json:ro
      - ./infrastructure/rabbitmq/init-rabbitmq.sh:/etc/rabbitmq/init-rabbitmq.sh:ro
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    profiles:
      - messaging

  # Celery Worker - Process async tasks
  celery-worker:
    build:
      context: ./python-ai-service
      dockerfile: ${DOCKERFILE:-Dockerfile}
    container_name: celery-worker
    restart: unless-stopped
    command: celery -A celery_app worker --loglevel=info --concurrency=4 --max-tasks-per-child=50
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
      - RABBITMQ_USER=${RABBITMQ_USER:-admin}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD:-rabbitmq_default_password}
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_VHOST=bot-core
      - REDIS_HOST=redis
      - REDIS_PASSWORD=${REDIS_PASSWORD:-redis_default_password}
      - DATABASE_URL=${DATABASE_URL:-mongodb://admin:secure_mongo_password_change_me@mongodb:27017/bot_core?authSource=admin}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - RUST_API_URL=http://rust-core-engine-dev:8080
      - PYTHON_API_URL=http://python-ai-service-dev:8000
    volumes:
      - ./python-ai-service:/app
      - ./python-ai-service/logs:/app/logs
      - ./python-ai-service/models:/app/models
    networks:
      - bot-network
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      python-ai-service-dev:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "celery -A celery_app inspect ping -d celery@$$HOSTNAME || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2"
        reservations:
          memory: 1G
          cpus: "1"
    profiles:
      - messaging

  # Celery Beat - Scheduler for periodic tasks
  celery-beat:
    build:
      context: ./python-ai-service
      dockerfile: ${DOCKERFILE:-Dockerfile}
    container_name: celery-beat
    restart: unless-stopped
    command: celery -A celery_app beat --loglevel=info
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
      - RABBITMQ_USER=${RABBITMQ_USER:-admin}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD:-rabbitmq_default_password}
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - RABBITMQ_VHOST=bot-core
      - REDIS_HOST=redis
      - REDIS_PASSWORD=${REDIS_PASSWORD:-redis_default_password}
      - DATABASE_URL=${DATABASE_URL:-mongodb://admin:secure_mongo_password_change_me@mongodb:27017/bot_core?authSource=admin}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - RUST_API_URL=http://rust-core-engine-dev:8080
      - PYTHON_API_URL=http://python-ai-service-dev:8000
    volumes:
      - ./python-ai-service:/app
      - ./python-ai-service/logs:/app/logs
    networks:
      - bot-network
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      python-ai-service-dev:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f 'celery.*beat' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
    profiles:
      - messaging

  # Flower - Celery monitoring dashboard
  flower:
    build:
      context: ./python-ai-service
      dockerfile: ${DOCKERFILE:-Dockerfile}
    container_name: flower
    restart: unless-stopped
    command: celery -A celery_app flower --port=5555 --basic_auth=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-admin}
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
      - MPLCONFIGDIR=/tmp/matplotlib
      - RABBITMQ_USER=${RABBITMQ_USER:-admin}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD:-rabbitmq_default_password}
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_VHOST=bot-core
      - RABBITMQ_MANAGEMENT_URL=http://rabbitmq:15672
      - REDIS_HOST=redis-cache
      - REDIS_PASSWORD=${REDIS_PASSWORD:-redis_default_password}
      - DATABASE_URL=${DATABASE_URL:-mongodb://admin:secure_mongo_password_change_me@mongodb:27017/bot_core?authSource=admin}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - RUST_API_URL=http://rust-core-engine-dev:8080
    volumes:
      - ./python-ai-service:/app
      - ./python-ai-service/logs:/app/logs
      - flower_tmp:/tmp
    ports:
      - "5555:5555"  # Flower web UI
    networks:
      - bot-network
    depends_on:
      rabbitmq:
        condition: service_healthy
      celery-worker:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f -u admin:admin http://localhost:5555/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 256M
    profiles:
      - messaging

  # Kong API Gateway
  kong-database:
    image: postgres:13-alpine
    container_name: kong-database
    restart: unless-stopped
    environment:
      - POSTGRES_DB=kong
      - POSTGRES_USER=kong
      - POSTGRES_PASSWORD=${KONG_DB_PASSWORD:-kong_db_default_password}
    volumes:
      - kong_data:/var/lib/postgresql/data
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "kong"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - api-gateway

  kong-migration:
    image: kong:3.8
    container_name: kong-migration
    command: kong migrations bootstrap
    depends_on:
      kong-database:
        condition: service_healthy
    environment:
      - KONG_DATABASE=postgres
      - KONG_PG_HOST=kong-database
      - KONG_PG_USER=kong
      - KONG_PG_PASSWORD=${KONG_DB_PASSWORD:-kong_db_default_password}
    networks:
      - bot-network
    restart: on-failure
    profiles:
      - api-gateway

  kong:
    image: kong:3.8
    container_name: kong
    restart: unless-stopped
    depends_on:
      kong-database:
        condition: service_healthy
      kong-migration:
        condition: service_completed_successfully
    environment:
      - KONG_DATABASE=postgres
      - KONG_PG_HOST=kong-database
      - KONG_PG_USER=kong
      - KONG_PG_PASSWORD=${KONG_DB_PASSWORD:-kong_db_default_password}
      - KONG_PROXY_ACCESS_LOG=/dev/stdout
      - KONG_ADMIN_ACCESS_LOG=/dev/stdout
      - KONG_PROXY_ERROR_LOG=/dev/stderr
      - KONG_ADMIN_ERROR_LOG=/dev/stderr
      - KONG_ADMIN_LISTEN=0.0.0.0:8001
      - KONG_DECLARATIVE_CONFIG=/opt/kong/kong.yml
    ports:
      - "8100:8000"  # Proxy (changed from 8000 to avoid conflict)
      - "8443:8443"  # Proxy SSL
      - "8001:8001"  # Admin API
      - "8444:8444"  # Admin SSL
    volumes:
      - ./infrastructure/kong/kong.yml:/opt/kong/kong.yml:ro
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - api-gateway

  # Prometheus monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - bot-network
    profiles:
      - monitoring

  # Grafana dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/monitoring/grafana:/etc/grafana/provisioning
      - ./infrastructure/grafana/init-grafana.sh:/etc/grafana/init-grafana.sh:ro
    networks:
      - bot-network
    depends_on:
      - prometheus
    profiles:
      - monitoring

networks:
  bot-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  mongodb_data:
    driver: local
  mongodb_config:
    driver: local
  redis_data:
    driver: local
  rabbitmq_data:
    driver: local
  kong_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  rust_target_cache:
    driver: local
  flower_tmp:
    driver: local
